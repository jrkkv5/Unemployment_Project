---
title: "Jeff"
author: "https://github.com/jrkkv5/FIN6572Fall2020/blob/master/National%20Debt/importNationalDebt.Rmd"
date: "11/8/2020"
output: html_document
---
```{r packages}
library(devtools)
library(blsAPI)
library(rjson)
library(curl)
library(RCurl)
library(knitr)
library(readr)
library(dplyr)
library(tidyverse)
library(rmarkdown)
library(pastecs)
library(ggplot2)
library(corrplot)
library(lmtest)
library(forecast)
#loads the necessary packages

```


Next, the data we collected is considered a time series as it was measured on an annual basis.  We used the unemployment data that was collected for each state and implemented a time series forecast using the Holt Method.  

Time series data typically contains four components: trend, seasonal, cyclical, and random components.  Trend is represented by the long-term movements in a data series, whether that be upward or downward.  Seasonality is normally represented by repetitions that occur within a single year time period, whereas the cyclical component represents long-term trends that are usually a factor the economy.  Typically, seasonal trends are easier to identify than cyclical trends because the time period of a seasonal trend is often known ahead of time.  Random components represent the random and unexplained movements within the time series data.

As the unemployment data we collected is shown on an annual basis, we will be focusing on the trend, cyclical, random components in our analysis.  The type of analysis we have chosen to focus on is called Holt Exponential Smoothing Method.  This method is characterized by incorporating large upward and downward fluctuations in data series.  This method is especially relevant because the dataset lacks seasonal variation.  

```{r IL Holt Analysis}

IL_TS <- ts(IL_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

IL_TData <- window(IL_TS, end = c(2004))
IL_VData <- window(IL_TS, start = c(2005))
#Partitions the training and validation sets
```
In the above section of code, we begin our Holt analysis of IL by creating the time series with the TS function.  We set the start and end values of our times series data equal to the time span our data stretches and set the frequency equal to one.

Using the window function we partition our dataset into a training set, IL_TData, and a validation set, IL_VData.

```{r IL Holt Analysis User}
IL_HUser <- ets(IL_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(IL_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```
It is common for practitioners to provide user supplied values for alpha and beta (smoothing parameters) due to the fact that the computer generated values are known to over-fit models where the data performed well in the sample period, but does not exhibit the same performance in the future.  In our data, we compare both user supplied and computer generated smoothing parameters.  We then compare the error measures to determine which model is a better fit to our data.  We used an alpha = 0.2 and beta = 0.15 when creating the user supplier parameters model.

The ets function above denotes the error, trend, and seasonality of the training set. The first letter in the model string represents that we want the error to be additive, the second letter represents that fact that we expect the trend type to be additive, and the third letter, "N", represents the fact that we do not intend on incorporating seasonality into our model.


```{r IL Holt Analysis Computer}
IL_HCmp <- ets(IL_TData, model = "AAN")
summary(IL_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```
We replicated the ets function using the computer generated smoothing parameters and obtained the output above. By comparing the root mean squared error(RMSE) and the mean absolute percentage error(MAPE) we can assess the fitness of the user supplier and computer generate models.  The user supplied model has a higher RMSE and MAPE indicating that the computer generated model provides a better overall fit for making a forecast. 

```{r IL Holt Set Forecast}
IL_nV <- length(IL_VData)
IL_fUser <- forecast(IL_HUser, h = IL_nV)
IL_fCmp <- forecast(IL_HCmp, h = IL_nV)
```
The length function is used to set the number of observations equal to the length of the validation set.
Then the forecast function is utilized to make a forecast based on the observations in our training set.

```{r IL Holt Analysis User Accuracy}
accuracy(IL_fUser,IL_VData)
```
```{r IL Holt Analysis Computer Accuracy}
accuracy(IL_fCmp,IL_VData)
```
The accuracy function is used to test the error term outputs that were created using the training set.  When comparing the accuracy function results we see conflicting results in our validation set.  The test set shows that the RMSE and MAPE of the user generated model provides a better fit for the performance of our data.  Ultimately, we decided to continue the process using the computer generated model, but the user supplied model would work just as well.
  
``` {r IL Holt Forecast}
IL_HFinal <- ets(IL_TS, model = "AAN")
forecast(IL_HFinal, h=1)
```
Finally, everything is brought together with the ets and forecast functions to forecast the unemployment level for the next period, 2019. The forecast generated shows that the expected value of the Illinois unemployment level in December 2019 is equal to 4.42% based on the trends that is observed in our model.  Based on the forecast we expect that the unemployment will range from 2.85% to 5.98% at a 80% confidence interval.  Additionally, we can be 95% confident that the unemployment value will fall between 2.02% and 6.81%. Based on the actual unemployment rate in IL for December 2019 of 3.5% our model was accurate at predicting the unemployment value at both the 95% and 80% confidence intervals.


```{r WV Holt Analysis}

WV_TS <- ts(WV_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

WV_TData <- window(WV_TS, end = c(2004))
WV_VData <- window(WV_TS, start = c(2005))
#Partitions the training and validation sets
```
```{r WV Holt Analysis User}
WV_HUser <- ets(WV_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(WV_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```
```{r WV Holt Analysis Computer}
WV_HCmp <- ets(WV_TData, model = "AAN")
summary(WV_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```
With West Virginia, we setup the datasets and partitioned them into training and validation sets following similar steps to Illinois.

The user supplied model for the state of West Virginia has a higher RMSE and MAPE at 1.4288 and 14.1598, respectively. The computer generated model has a RMSE of 0.9736 and a MAPE of 8.5906 indicating that the computer generated model provides a better overall fit to our forecast. 

```{r WV Holt Set Forecast}
WV_nV <- length(WV_VData)
WV_fUser <- forecast(WV_HUser, h = WV_nV)
WV_fCmp <- forecast(WV_HCmp, h = WV_nV)
```
```{r WV Holt Analysis User Accuracy}
accuracy(WV_fUser,WV_VData)
```
```{r WV Holt Analysis Computer Accuracy}
accuracy(WV_fCmp,WV_VData)
```

The accuracy function confirms that the computer generated model is a better overall fit to the data we are using to create the model.  This is due to the fact that once again the validation set exhibits a lower RMSE and MAPE under the computer generated model.

``` {r WV Holt Forecast}
WV_HFinal <- ets(WV_TS, model = "AAN")
forecast(WV_HFinal, h=1)
```

The forecast for West Virginia shows us that the expected value of the unemployment level in December 2019 is equal to 4.70% based on the trends that were observed in the computer generated model. At an 80% confidence interval we expect West Virginia's unemployment level to range from 3.20% to 6.20%.  Additionally, we can be 95% confident that the unemployment rate will be in the 2.41% to 6.99% level. The actual unemployment rate for the State of West Virginia in December 2019 is 5%. Our model is accurate at both the 95% and 80% confidence intervals.  5% is also fairly close to the point estimate at 4.7% further signifying that our model produces accurate results.