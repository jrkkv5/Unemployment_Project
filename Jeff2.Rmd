---
title: "Jeff2"
author: "https://github.com/jrkkv5/FIN6572Fall2020/blob/master/National%20Debt/importNationalDebt.Rmd"
date: "11/28/2020"
output: html_document
---

```{r library}
#Loading necessary packages
library(readr)
library(devtools)
library(blsAPI)
library(rjson)
library(curl)
library(dplyr)
library(tidyverse)
library(rmarkdown)
library(knitr)
library(pastecs)
library(ggplot2)
library(corrplot)
library(lmtest)
library(forecast)

#Update code for your states and run regression from 1984-2014, create some basic plots, etc.
```

``` {r log variables}
merged_final <- read_csv("csv files/mergedFinal.csv")
#Reads final file into merged dataframe

merged_final$log_pop = log(merged_final$population)

merged_final$log_RMHI = log(merged_final$RMHI)
```
As a final step in scrubbing our data, we created new variables to log the population and median household income variables and store it in our dataframe. By taking the logarithmic values, these variables become more comparable to the existing variables we have within our dataset.

Below you can see the table output once all of our data has been merged.
``` {r merged_final_table}

kable(merged_final[1:6,], caption = "Table Including All Variables")
```
After our data was merged we binned the states into groups based on the mean population of the years in our dataframe (1984-2018).  Below are the bins that were created:

Population < 2,000,000
WV, NM, NE, ID, ME, HI, NH, RI, MT, DE, SD, ND, AK, VT, WY

2,000,000 < Population < 5,000,000
MN, AL, LA, CO, SC, KY, OK, OR, CT, IA, MS, KS, AR, UT, NV

5,000,000 < Population < 10,000,000
MI, NJ, GA, NC, VA, MA, IN, WA, TN, MO, WI, MD, AZ

Population > 2,000,000
CA, TX, NY, FL, PA, IL, OH


Each member of our group performed some basic analysis on the states within one of the bins. After performing our initial analysis we chose to focus on 2 states within each bin.  The states we chose to focus on are: TX, IL, MO, WA, XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX


Below are some of the highlights along with commentary for the states we have chosen to focus on 

```{r IL Analysis}
IL_data <- merged_final[ merged_final$state == "IL", ]

scatter.smooth(IL_data$year, IL_data$value, main="IL Unemployment by Year", xlab = "Year", ylab = "Unemployment", col = "blue", span = 2/3)

scatter.smooth(IL_data$year, IL_data$HPI, main="IL HPI by Year", xlab = "Year", ylab = "HPI", col = "blue")

scatter.smooth(x=IL_data$year, y=IL_data$value, main="IL Unemployment by Year", xlab = "Year", ylab = "Unemployment", col = "red")

scatter.smooth(x=IL_data$year, y=IL_data$poverty, main="IL % of People Below Poverty Level", xlab = "Year", ylab = "Poverty", ylim = c(0,20))

IL_data$RMHI <- as.integer(IL_data$RMHI)
plot(x=IL_data$year, y=IL_data$RMHI, main="IL Median Household Income by Year", xlab = "Year", ylab = "RMHI" )

IL_data$population <- as.integer(IL_data$population)
plot(x=IL_data$year, y=IL_data$population, main="IL Population by Year", xlab = "Year", ylab = "Population" )

IL_data$log_RMHI <- as.integer(IL_data$log_RMHI)
plot(x=IL_data$year, y=IL_data$log_RMHI, main="IL Median Household Income by Year", xlab = "Year", ylab = "log_RMHI" )

IL_data$log_pop <- as.integer(IL_data$log_pop)
plot(x=IL_data$year, y=IL_data$log_pop, main="IL Population by Year", xlab = "Year", ylab = "log_Population" )

cor(IL_data$RMHI, IL_data$value)
cor(IL_data$HPI, IL_data$value)
cor(IL_data$poverty, IL_data$value)
cor(IL_data$population, IL_data$value)
cor(IL_data$sp500, IL_data$value)
#run base correlations between categories and dependent variable

par(mfrow=c(1, 2))  # divide graph area in 2 columns
boxplot(IL_data$value, main="Unemployment", sub=paste("Outlier rows: ", boxplot.stats(IL_data$value)$out))  # box plot for 'Unemployment'
boxplot(IL_data$poverty, main="Poverty", sub=paste("Outlier rows: ", boxplot.stats(IL_data$poverty)$out))  # box plot for 'Poverty'
#create box plot for poverty level and unemployment level

#run multiple linear model for data
IL_reg1 <- lm(value ~ poverty + RMHI + HPI + population + sp500, data = IL_data)
summary(IL_reg1)
anova(IL_reg1)

IL_reg2 <- lm(value ~ poverty + log_RMHI + HPI + log_pop + sp500, data = IL_data)
summary(IL_reg2)
anova(IL_reg2)

IL_linearModelSignificant <- lm(value ~ poverty + population, data = IL_data)
summary(IL_linearModelSignificant)

#test to show a scatterplot IL HPI data against year
```




```{r TX Analysis}
TX_data <- merged_final[ merged_final$state == "TX", ]

scatter.smooth(TX_data$year, TX_data$value, main="TX Unemployment by Year", xlab = "Year", ylab = "Unemployment", col = "blue", span = 2/3)

scatter.smooth(TX_data$year, TX_data$HPI, main="TX HPI by Year", xlab = "Year", ylab = "HPI", col = "blue")

scatter.smooth(x=TX_data$year, y=TX_data$value, main="TX Unemployment by Year", xlab = "Year", ylab = "Unemployment", col = "red")

scatter.smooth(x=TX_data$year, y=TX_data$poverty, main="TX % of People Below Poverty Level", xlab = "Year", ylab = "Poverty", ylim = c(0,20))

TX_data$RMHI <- as.integer(TX_data$RMHI)
plot(x=TX_data$year, y=TX_data$RMHI, main="TX Median Household Income by Year", xlab = "Year", ylab = "RMHI" )

TX_data$population <- as.integer(TX_data$population)
plot(x=TX_data$year, y=TX_data$population, main="TX Population by Year", xlab = "Year", ylab = "Population" )

TX_data$log_RMHI <- as.integer(TX_data$log_RMHI)
plot(x=TX_data$year, y=TX_data$log_RMHI, main="TX Median Household Income by Year", xlab = "Year", ylab = "log_RMHI" )

TX_data$log_pop <- as.integer(TX_data$log_pop)
plot(x=TX_data$year, y=TX_data$log_pop, main="TX Population by Year", xlab = "Year", ylab = "log_Population" )

cor(TX_data$RMHI, TX_data$value)
cor(TX_data$HPI, TX_data$value)
cor(TX_data$poverty, TX_data$value)
cor(TX_data$population, TX_data$value)
cor(TX_data$sp500, TX_data$value)
#run base correlations between categories and dependent variable

par(mfrow=c(1, 2))  # divide graph area in 2 columns
boxplot(TX_data$value, main="Unemployment", sub=paste("Outlier rows: ", boxplot.stats(TX_data$value)$out))  # box plot for 'Unemployment'
boxplot(TX_data$poverty, main="Poverty", sub=paste("Outlier rows: ", boxplot.stats(TX_data$poverty)$out))  # box plot for 'Poverty'
#create box plot for poverty level and unemployment level

#run multiple linear model for data
TX_reg1 <- lm(value ~ poverty + RMHI + HPI + population + sp500, data = TX_data)
summary(TX_reg1)
anova(TX_reg1)

TX_reg2 <- lm(value ~ poverty + log_RMHI + HPI + log_pop + sp500, data = TX_data)
summary(TX_reg2)
anova(TX_reg2)

TX_linearModelSignificant <- lm(value ~ poverty + population, data = TX_data)
summary(TX_linearModelSignificant)

#test to show a scatterplot TX HPI data against year
```



```{r main data analysis}
#my states:WA, MO
merged_final.F <- read_csv("csv files/mergedFinal.csv")

#Logging
merged_final.F$log_pop = log(merged_final$population)
merged_final.F$log_RMHI = log(merged_final$RMHI)

#Descriptive Statistics
stat.desc(merged_final.F)

#Pairwise Correlations
sapply(merged_final.F, class)
sapply(merged_final.F, is.factor)
cor(merged_final.F[sapply(merged_final.F, function(x) !is.character(x))])

```

```{r MO Analysis}
MO_data <- merged_final.F[ merged_final.F$state == "MO", ]
```

```{r MO scatter log population}
MO_data$log_pop <- as.integer(MO_data$log_pop)
plot(x=MO_data$year, y=MO_data$log_pop, main="IL Log Population by Year", xlab = "Year", ylab = "log_Population",ylim = c(14,16))
```
```{r TX Analysis}
TX_data <- merged_final[ merged_final$state == "TX", ]
```

```{r TX Histogram Unemployment}
hist(TX_data$value,
     main="Histogram of Unemployment Across All 50 States",
     xlim=c(4,11),
     xlab="Unemployment Rate",
     breaks = 5)
```

```{r TX Histogram Poverty}
hist(TX_data$poverty,
     main="Histogram of Poverty Across All 50 States",
     xlim=c(9,16),
     xlab="Poverty Rate",
     breaks = 5)
```

```{r TX scatter unemployment}
scatter.smooth(TX_data$year, TX_data$value, main="TX Unemployment by Year", xlab = "Year", ylab = "Unemployment", col = "blue", span = 2/8)
```

```{r TX scatter HPI}
scatter.smooth(TX_data$year, TX_data$HPI, main="TX HPI by Year", xlab = "Year", ylab = "HPI", col = "blue", span = 2/8)
```

```{r TX scatter poverty}
scatter.smooth(x=TX_data$year, y=TX_data$poverty, main="TX % of People Below Poverty Level", xlab = "Year", ylab = "Poverty", ylim = c(0,20), span = 2/8)
```

```{r TX scatter RMHI}
TX_data$RMHI <- as.integer(TX_data$RMHI)
scatter.smooth(x=TX_data$year, y=TX_data$RMHI, main="TX Median Household Income by Year", xlab = "Year", ylab = "RMHI", span = 2/8 )
```

```{r TX scatter population}
TX_data$population <- as.integer(TX_data$population)
scatter.smooth(x=TX_data$year, y=TX_data$population, main="TX Population by Year", xlab = "Year", ylab = "Population", span = 2/8 )
```

```{r TX scatter log RMHI}
#TX_data$log_RMHI <- as.integer(TX_data$log_RMHI)
scatter.smooth(x=TX_data$year, y=TX_data$log_RMHI, main="TX Log Median Household Income by Year", xlab = "Year", ylab = "log_RMHI", span = 2/8 )
```

```{r TX scatter log population}
#TX_data$log_pop <- as.integer(TX_data$log_pop)
scatter.smooth(x=TX_data$year, y=TX_data$log_pop, main="TX Log Population by Year", xlab = "Year", ylab = "log_Population", span = 2/8)
```

```{r TX correlations}
cor(TX_data$RMHI, TX_data$value)
cor(TX_data$HPI, TX_data$value)
cor(TX_data$poverty, TX_data$value)
cor(TX_data$population, TX_data$value)
cor(TX_data$sp500, TX_data$value)
cor(TX_data$log_pop, TX_data$value)
cor(TX_data$log_RMHI, TX_data$value)
#run base correlations between categories and dependent variable
```

```{r TX boxplot unemployment}
par(mfrow=c(1, 2))  # divide graph area in 2 columns
boxplot(TX_data$value, main="Unemployment", sub=paste("Outlier rows: ", boxplot.stats(TX_data$value)$out))  # box plot for 'Unemployment'
```

```{r TX boxplot poverty}
boxplot(TX_data$poverty, main="Poverty", sub=paste("Outlier rows: ", boxplot.stats(TX_data$poverty)$out))  # box plot for 'Poverty'
#create box plot for poverty level and unemployment level
```

```{r TX linear regression all}
#run multiple linear model for data
TX_reg1 <- lm(value ~ poverty + RMHI + HPI + population + sp500, data = TX_data)
summary(TX_reg1)
anova(TX_reg1)
```

```{r TX linear regression log all}
TX_reg2 <- lm(value ~ poverty + log_RMHI + HPI + log_pop + sp500, data = TX_data)
summary(TX_reg2)
anova(TX_reg2)
```

```{r TX linear significant variables}
TX_linearModelSignificant <- lm(value ~ poverty + log_pop, data = TX_data)
summary(TX_linearModelSignificant)

#test to show a scatterplot TX HPI data against year
```
```{r IL Timeseries Analysis}

IL_TS <- ts(IL_data$value, start = c(1984,1), end = c(2018,1), frequency = 1)
#Stores start, end, and frequency of timeseries data

IL_TS_reg <- tslm(IL_TS ~ trend)
#Stores regression model of timeseries data.
summary(IL_TS_reg)

forecast(IL_TS_reg, 3)
#note 3 denots the number of forecasts.
 plot(IL_TS)
```

```{r IL Holt Analysis}

IL_TS <- ts(IL_data$value, start = c(1984), end = c(2017), frequency = 1)
#Stores start, end, and frequency of timeseries data

IL_TData <- window(IL_TS, end = c(2013))
IL_VData <- window(IL_TS, start = c(2014))
#Partitions the training and validation sets

IL_HUser <- ets(IL_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(IL_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.

IL_HCmp <- ets(IL_TData, model = "AAN")
summary(IL_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.

IL_nV <- length(IL_VData)
IL_fUser <- forecast(IL_HUser, h = IL_nV)
IL_fCmp <- forecast(IL_HCmp, h = IL_nV)
accuracy(IL_fUser,IL_VData)
accuracy(IL_fCmp,IL_VData)

```
``` {r IL Holt Forecast}

IL_HFinal <- ets(IL_TS, model = "AAN")
forecast(IL_HFinal, h=2)
#print(IL_data$value, year == "2018")
```

```{r TX Holt Analysis}

TX_TS <- ts(TX_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

TX_TData <- window(TX_TS, end = c(2004))
TX_VData <- window(TX_TS, start = c(2005))
#Partitions the training and validation sets
```

```{r TX Holt Analysis User}
TX_HUser <- ets(TX_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(TX_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```

```{r TX Holt Analysis Computer}
TX_HCmp <- ets(TX_TData, model = "AAN")
summary(TX_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```
```{r TX Holt Set Forecast}
TX_nV <- length(TX_VData)
TX_fUser <- forecast(TX_HUser, h = TX_nV)
TX_fCmp <- forecast(TX_HCmp, h = TX_nV)
```


```{r TX Holt Analysis User Accuracy}
accuracy(TX_fUser,TX_VData)
```


```{r TX Holt Analysis Computer Accuracy}
accuracy(TX_fCmp,TX_VData)
```

``` {r TX Holt Forecast}
TX_HFinal <- ets(TX_TS, model = "AAN")
forecast(TX_HFinal, h=1)
```





























Next, the data we collected is considered a time series as it was measured on an annual basis.  We used the unemployment data that was collected for each state and implemented a time series forecast using the Holt Method.  

Time series data typically contains four components: trend, seasonal, cyclical, and random components.  Trend is represented by the long-term movements in the data series, whether that be upward or downward.  A seasonal component normally represents repetitions that occur within a single year time period, whereas the cyclical component represents long-term trends that are usually a factor the economy.  Typically, seasonal trends are easier to identify than cyclical trends because the time period of the seasonal trend is often known ahead of time.  Random components represent the random and unexplained movements within the time series data.

As our unemployment data is shown on an annual basis, we will be focusing on the trend, cyclical, random components in our analysis.  The type of analysis we have chosen to focus on is labeled the Holt Exponential Smoothing Method.  This method is characterized by incorporating the large upward and downward fluctuations in the series and is most appropriate when the dataset lacks seasonal variation.  We went into greater detail explaining the process that was used on IL, but for the other states we will simply analyze the model and the results.


```{r IL Holt Analysis}

IL_TS <- ts(IL_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

IL_TData <- window(IL_TS, end = c(2004))
IL_VData <- window(IL_TS, start = c(2005))
#Partitions the training and validation sets
```
In the above section of code, we begin our time series analysis of IL by creating the time series with the TS function.  We set the start and end values of our times series data equal to the time span our data streches and set the frequency equal to one.

Using the window function we partition our dataset into a training set, IL_TData, and a validation set, IL_VData.

```{r IL Holt Analysis User}
IL_HUser <- ets(IL_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(IL_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```
It is common for practitioners to provide user supplied values for alpha and beta (smoothing parameters) due to the fact that the computer generated values are known to over-fit models where the data performed well in the sample period, but does not exhibit the same performance in the future.  In our data, we will compare both user supplied and computer generated smoothing parameters.  We will then compare the error measures to determine which model is a better fit to our data.  We used an alpha = 0.2 and beta = 0.15 when creating our user supplier parameters model.

The ets function above denotes the error, trend, and seasonality of the training set, respectively. The first letter in the model string represents that we want the error to be additive, the second letter represents that fact that we expect the trend type to be additive, and the third letter represents the fact that we do not intend on incorporating seasonality into our model.


```{r IL Holt Analysis Computer}
IL_HCmp <- ets(IL_TData, model = "AAN")
summary(IL_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```
By comparing the root mean squared error(RMSE) and the mean absolute percentage error(MAPE) we can assess the fitness of the user supplier and computer generate models.  The user supplied model has a higher RMSE and MAPE indicating that the computer generated model provides a better overall fit to our forecast. 

```{r IL Holt Set Forecast}
IL_nV <- length(IL_VData)
IL_fUser <- forecast(IL_HUser, h = IL_nV)
IL_fCmp <- forecast(IL_HCmp, h = IL_nV)
```
The length function above was used to set the number of observations equal to the length of the validation set.
Then the forecast function was used to make a forecast based on the observations in our training set.

```{r IL Holt Analysis User Accuracy}
accuracy(IL_fUser,IL_VData)
```
```{r IL Holt Analysis Computer Accuracy}
accuracy(IL_fCmp,IL_VData)
```
When comparing the accuracy function results we see conflicting results in our validation set.  The test set shows that the RMSE and MAPE of the user generated model provides a better fit for the performance of our data.  Ultimately, we decided to continue the process using the computer generated model, but the user supplied model would work just as well.
  
``` {r IL Holt Forecast}
IL_HFinal <- ets(IL_TS, model = "AAN")
forecast(IL_HFinal, h=1)
```
Finally, we bring everything together with the ets function and forecast the unemployment level for the next period, 2019. The forecast that was generated shows us that the expected value of the Illinois unemployment level in December 2019 is equal to 4.42% based on the trends that were observed in our model.



```{r TX Holt Analysis}

TX_TS <- ts(TX_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

TX_TData <- window(TX_TS, end = c(2004))
TX_VData <- window(TX_TS, start = c(2005))
#Partitions the training and validation sets
```

```{r TX Holt Analysis User}
TX_HUser <- ets(TX_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(TX_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```

```{r TX Holt Analysis Computer}
TX_HCmp <- ets(TX_TData, model = "AAN")
summary(TX_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```
The user supplied model for the state of Texas has a higher RMSE and MAPE at 1.0227 and 14.7904 respectively. The computer generated model has a RMSE of 0.8366 and a MAPE of 11.3532 indicating that the computer generated model provides a better overall fit to our forecast. 

```{r TX Holt Set Forecast}
TX_nV <- length(TX_VData)
TX_fUser <- forecast(TX_HUser, h = TX_nV)
TX_fCmp <- forecast(TX_HCmp, h = TX_nV)
```
```{r TX Holt Analysis User Accuracy}
accuracy(TX_fUser,TX_VData)
```
```{r TX Holt Analysis Computer Accuracy}
accuracy(TX_fCmp,TX_VData)
```
The accuracy function confirms that the computer generated model is a better overall fit to the data we are using to create our model.  This is due to the fact that once again the validation set exhibits a lower RMSE and MAPE.

``` {r TX Holt Forecast}
TX_HFinal <- ets(TX_TS, model = "AAN")
forecast(TX_HFinal, h=1)
```
The forecast that was generated shows us that the expected value of the Texas unemployment level in December 2019 is equal to 3.79% based on the trends that were observed in our model.



```{r MO Holt Analysis}

MO_TS <- ts(MO_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

MO_TData <- window(MO_TS, end = c(2004))
MO_VData <- window(MO_TS, start = c(2005))
#Partitions the training and validation sets
```

```{r MO Holt Analysis User}
MO_HUser <- ets(MO_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(MO_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```

```{r MO Holt Analysis Computer}
MO_HCmp <- ets(MO_TData, model = "AAN")
summary(MO_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```
The user supplied model for the state of Missouri has a higher RMSE and MAPE at 0.9134 and 16.6072 respectively. The computer generated model has a RMSE of 0.6557 and a MAPE of 11.5924 indicating that the computer generated model provides a better overall fit to our forecast. 
```{r MO Holt Set Forecast}
MO_nV <- length(MO_VData)
MO_fUser <- forecast(MO_HUser, h = MO_nV)
MO_fCmp <- forecast(MO_HCmp, h = MO_nV)
```
```{r MO Holt Analysis User Accuracy}
accuracy(MO_fUser,MO_VData)
```
```{r MO Holt Analysis Computer Accuracy}
accuracy(MO_fCmp,MO_VData)
```
The results from the accuracy function conflict with our initial assessment. The accuracy function shows that in the validation set, the RMSE and MAPE of the user defined model are lower and indicate there is a better overall fit to the data. For this exercise we will proceed with the computer generated model.
``` {r MO Holt Forecast}
MO_HFinal <- ets(MO_TS, model = "AAN")
forecast(MO_HFinal, h=1)
```
The forecast that was generated shows us that the expected value of the Missouri unemployment level in December 2019 is equal to 2.94% based on the trends that were observed in our model.


```{r WA Holt Analysis}

WA_TS <- ts(WA_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

WA_TData <- window(WA_TS, end = c(2004))
WA_VData <- window(WA_TS, start = c(2005))
#Partitions the training and validation sets
```

```{r WA Holt Analysis User}
WA_HUser <- ets(WA_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(WA_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```

```{r WA Holt Analysis Computer}
WA_HCmp <- ets(WA_TData, model = "AAN")
summary(WA_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```

The user supplied model for the state of Washington has a higher RMSE and MAPE at 1.1583 and 14.6664 respectively. The computer generated model has a RMSE of 0.8353 and a MAPE of 10.6124 indicating that the computer generated model provides a better overall fit to our forecast. 

```{r WA Holt Set Forecast}
WA_nV <- length(WA_VData)
WA_fUser <- forecast(WA_HUser, h = WA_nV)
WA_fCmp <- forecast(WA_HCmp, h = WA_nV)
```
```{r WA Holt Analysis User Accuracy}
accuracy(WA_fUser,WA_VData)
```
```{r WA Holt Analysis Computer Accuracy}
accuracy(WA_fCmp,WA_VData)
```

The results from the accuracy function conflict with our initial assessment. The accuracy function shows that in the validation set, the RMSE and MAPE of the user defined model are lower and indicate there is a better overall fit to the data. For this exercise we will proceed with the computer generated model.

``` {r WA Holt Forecast}
WA_HFinal <- ets(WA_TS, model = "AAN")
forecast(WA_HFinal, h=1)
```
The forecast that was generated shows us that the expected value of the Washington unemployment level in December 2019 is equal to 4.63% based on the trends that were observed in our model.


```{r OR Holt Analysis}

OR_TS <- ts(OR_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

OR_TData <- window(OR_TS, end = c(2004))
OR_VData <- window(OR_TS, start = c(2005))
#Partitions the training and validation sets
```
```{r OR Holt Analysis User}
OR_HUser <- ets(OR_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(OR_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```
```{r OR Holt Analysis Computer}
OR_HCmp <- ets(OR_TData, model = "AAN")
summary(OR_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```

The user supplied model for the state of Oregon has a higher RMSE and MAPE at 1.2116 and 14.9369 respectively. The computer generated model has a RMSE of 1.0738 and a MAPE of 13.2990 indicating that the computer generated model provides a better overall fit to our forecast. 

```{r OR Holt Set Forecast}
OR_nV <- length(OR_VData)
OR_fUser <- forecast(OR_HUser, h = OR_nV)
OR_fCmp <- forecast(OR_HCmp, h = OR_nV)
```
```{r OR Holt Analysis User Accuracy}
accuracy(OR_fUser,OR_VData)
```
```{r OR Holt Analysis Computer Accuracy}
accuracy(OR_fCmp,OR_VData)
```
The results from the accuracy function conflict with our initial assessment. The accuracy function shows that in the validation set, the RMSE of the user defined model is lower and indicate there is a better overall fit to the data. The MAPE of the validation set confirms our initial assessment that the computer generated model provides a better overall fit. For this exercise we will proceed with the computer generated model.

``` {r OR Holt Forecast}
OR_HFinal <- ets(OR_TS, model = "AAN")
forecast(OR_HFinal, h=1)
```
The forecast that was generated shows us that the expected value of the Oregon unemployment level in December 2019 is equal to 3.7678% based on the trends that were observed in our model.

```{r CO Holt Analysis}

CO_TS <- ts(CO_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

CO_TData <- window(CO_TS, end = c(2004))
CO_VData <- window(CO_TS, start = c(2005))
#Partitions the training and validation sets
```
```{r CO Holt Analysis User}
CO_HUser <- ets(CO_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(CO_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```
```{r CO Holt Analysis Computer}
CO_HCmp <- ets(CO_TData, model = "AAN")
summary(CO_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```
The user supplied model for the state of Colorado has a higher RMSE and MAPE at 1.2473 and 18.2991 respectively. The computer generated model has a RMSE of 0.9833 and a MAPE of 15.5345 indicating that the computer generated model provides a better overall fit to our forecast. 

```{r CO Holt Set Forecast}
CO_nV <- length(CO_VData)
CO_fUser <- forecast(CO_HUser, h = CO_nV)
CO_fCmp <- forecast(CO_HCmp, h = CO_nV)
```
```{r CO Holt Analysis User Accuracy}
accuracy(CO_fUser,CO_VData)
```

```{r CO Holt Analysis Computer Accuracy}
accuracy(CO_fCmp,CO_VData)
```

The accuracy function confirms that the computer generated model is a better overall fit to the data we are using to create our model.  This is due to the fact that once again the validation set exhibits a lower RMSE and MAPE.

``` {r CO Holt Forecast}
CO_HFinal <- ets(CO_TS, model = "AAN")
forecast(CO_HFinal, h=1)
```

The forecast that was generated shows us that the expected value of the Colorado unemployment level in December 2019 is equal to 2.7246% based on the trends that were observed in our model.

```{r WV Holt Analysis}

WV_TS <- ts(WV_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

WV_TData <- window(WV_TS, end = c(2004))
WV_VData <- window(WV_TS, start = c(2005))
#Partitions the training and validation sets
```
```{r WV Holt Analysis User}
WV_HUser <- ets(WV_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(WV_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```
```{r WV Holt Analysis Computer}
WV_HCmp <- ets(WV_TData, model = "AAN")
summary(WV_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```

The user supplied model for the state of West Virginia has a higher RMSE and MAPE at 1.4288 and 14.1598 respectively. The computer generated model has a RMSE of 0.9736 and a MAPE of 8.5906 indicating that the computer generated model provides a better overall fit to our forecast. 

```{r WV Holt Set Forecast}
WV_nV <- length(WV_VData)
WV_fUser <- forecast(WV_HUser, h = WV_nV)
WV_fCmp <- forecast(WV_HCmp, h = WV_nV)
```
```{r WV Holt Analysis User Accuracy}
accuracy(WV_fUser,WV_VData)
```
```{r WV Holt Analysis Computer Accuracy}
accuracy(WV_fCmp,WV_VData)
```

The accuracy function confirms that the computer generated model is a better overall fit to the data we are using to create our model.  This is due to the fact that once again the validation set exhibits a lower RMSE and MAPE.

``` {r WV Holt Forecast}
WV_HFinal <- ets(WV_TS, model = "AAN")
forecast(WV_HFinal, h=1)
```

The forecast that was generated shows us that the expected value of the West Virginia unemployment level in December 2019 is equal to 4.70% based on the trends that were observed in our model.

```{r ME Holt Analysis}

ME_TS <- ts(ME_data$value, start = c(1984), end = c(2018), frequency = 1)
#Stores start, end, and frequency of timeseries data

ME_TData <- window(ME_TS, end = c(2004))
ME_VData <- window(ME_TS, start = c(2005))
#Partitions the training and validation sets
```
```{r ME Holt Analysis User}
ME_HUser <- ets(ME_TData, model = "AAN", alpha = 0.2, beta = 0.15)
summary(ME_HUser)
#Training data set using user based parameters for alpha and beta for smoothing.
```
```{r ME Holt Analysis Computer}
ME_HCmp <- ets(ME_TData, model = "AAN")
summary(ME_HCmp)
#Training data set using computer based parameters for alpha and beta for smoothing.
```

The user supplied model for the state of Maine has a higher RMSE and MAPE at 1.4430 and 26.5876 respectively. The computer generated model has a RMSE of 0.8670 and a MAPE of 12.1342 indicating that the computer generated model provides a better overall fit to our forecast. 

```{r ME Holt Set Forecast}
ME_nV <- length(ME_VData)
ME_fUser <- forecast(ME_HUser, h = ME_nV)
ME_fCmp <- forecast(ME_HCmp, h = ME_nV)
```
```{r ME Holt Analysis User Accuracy}
accuracy(ME_fUser,ME_VData)
```
```{r ME Holt Analysis Computer Accuracy}
accuracy(ME_fCmp,ME_VData)
```

The accuracy function confirms that the computer generated model is a better overall fit to the data we are using to create our model.  This is due to the fact that once again the validation set exhibits a lower RMSE and MAPE.

``` {r ME Holt Forecast}
ME_HFinal <- ets(ME_TS, model = "AAN")
forecast(ME_HFinal, h=1)
```
The forecast that was generated shows us that the expected value of the Maine unemployment level in December 2019 is equal to 2.6793% based on the trends that were observed in our model.






